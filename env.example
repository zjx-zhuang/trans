# Logging Configuration
# Options: DEBUG, INFO, WARNING, ERROR
LOG_LEVEL=INFO

# LLM Provider Configuration
# Options: "gemini" or "openai"
LLM_PROVIDER=gemini

# Google Gemini via Vertex AI Configuration (required if LLM_PROVIDER=gemini)
# Uses Application Default Credentials (ADC) for authentication.
# Run 'gcloud auth application-default login' to set up local credentials.
# Optional: Override the project ID (defaults to ADC project)
GOOGLE_CLOUD_PROJECT=your_gcp_project_id_here
# Optional: Override the location (defaults to us-central1)
GOOGLE_CLOUD_LOCATION=us-central1
# Optional: Override the model (defaults to gemini-2.5-flash)
GEMINI_MODEL=gemini-2.5-flash

# OpenAI Configuration (required if LLM_PROVIDER=openai)
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_MODEL=gpt-4o
# Optional: Custom API base URL for third-party OpenAI-compatible services
# Examples: https://api.openai-proxy.com/v1, https://your-azure-endpoint.openai.azure.com
OPENAI_API_BASE=

# Hive Validation Mode
# Options: "enabled" (default, use LLM to validate Hive SQL before conversion)
#          "disabled" / "skip" / "off" (skip Hive validation, go directly to conversion)
HIVE_VALIDATION_MODE=enabled

# BigQuery Validation Mode
# Options: "dry_run" (use BigQuery API) or "llm" (use LLM prompt-based validation)
BQ_VALIDATION_MODE=dry_run

# Maximum Retry Attempts
# Number of times to retry fixing BigQuery SQL if validation fails (default: 1)
MAX_RETRIES=1

# SQL Chunking Configuration
# For long SQL statements, the converter can split them into chunks for better accuracy.
# Options: "auto" (default, chunk when SQL > MAX_SQL_LENGTH or MAX_SQL_LINES),
#          "always" (always chunk), "disabled" (never chunk)
SQL_CHUNKING_MODE=auto
# Thresholds for auto-chunking (when SQL exceeds these limits)
MAX_SQL_LENGTH=8000
MAX_SQL_LINES=200

# GCP Service Account Credentials Path (optional, uses ADC if not set)
# GOOGLE_APPLICATION_CREDENTIALS=/path/to/your/service-account-key.json
